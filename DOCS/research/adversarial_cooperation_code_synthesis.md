<span id="1"></span>

<div id="page1-div"
style="position:relative;width:918px;height:1188px;">

Â 

**BlockÂ AIÂ ResearchÂ **

**Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â **

**Â **

**Â **

**Â **

**Â **

**Â **

**Â **

**Â Â Â Â Â Â Â **DecemberÂ 8,Â 2025Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

**Â   
AdversarialÂ CooperationÂ Â   
InÂ CodeÂ SynthesisÂ   
**AÂ NewÂ ParadigmÂ ForÂ AIî‚ˆAssistedÂ 

SoftwareÂ Development

**Â **

</div>

<span id="2"></span>

<div id="page2-div"
style="position:relative;width:918px;height:1188px;">

**Abstract**

**Â **

ThisÂ paperÂ introducesÂ **dialecticalÂ autocoding:**Â aÂ novelÂ approachÂ toÂ AI-assistedÂ softwareÂ   
developmentÂ thatÂ transcendsÂ theÂ limitationsÂ ofÂ currentÂ vibeÂ codingÂ toolsÂ throughÂ aÂ   
structuredÂ coach-playerÂ feedbackÂ loop.Â Â 

ByÂ implementingÂ aÂ bounded,Â adversarialÂ processÂ betweenÂ twoÂ cooperatingÂ agents,Â weÂ   
demonstrateÂ howÂ intelligentÂ AIÂ programsÂ canÂ makeÂ substantiallyÂ moreÂ progressÂ onÂ complexÂ   
codingÂ tasks,Â resultingÂ inÂ betterÂ tested,Â moreÂ robustÂ implementations,Â whileÂ workingÂ aroundÂ   
fundamentalÂ attentionÂ andÂ human-in-the-loopÂ limitations.Â Â 

OurÂ exampleÂ implementation,[Â g31](https://github.com/dhanji/g3),Â demonstratesÂ howÂ thisÂ approachÂ isÂ ableÂ toÂ fullyÂ   
automateÂ human-agentÂ codingÂ sessionsÂ forÂ aÂ broadÂ varietyÂ ofÂ tasks.Â 

Â 

Â 

1[Â https://github.com/dhanji/g3](https://github.com/dhanji/g3)Â Â   
Â 

Â 

**Â **

1Â 

Â 

</div>

<span id="3"></span>

<div id="page3-div"
style="position:relative;width:918px;height:1188px;">

**TableÂ ofÂ ContentsÂ   
**Â 

**Â **

**AbstractÂ **

**Â **

**IntroductionÂ **

Â 

Â Â Â Â Â Â Â Â Â Â TheÂ CurrentÂ StateÂ ofÂ AIÂ CodingÂ 

Â 

Â Â Â Â Â Â Â Â Â Â TheÂ PromiseÂ ofÂ AutonomousÂ ProgrammingÂ 

**Â **

**AdversarialÂ CooperationÂ **

Â 

**ContextÂ WindowÂ ManagementÂ **

Â 

**ModelÂ UtilizationÂ **

Â 

**AutocodingÂ vs.Â Single-TurnÂ â€œVibeÂ CodingË®Â **

Â 

**EmpiricalÂ ResultsÂ andÂ CaseÂ StudiesÂ **

Â 

Â Â Â Â Â Â Â Â Â Â Â Â CaseÂ Study:Â CalculatorÂ APIÂ 

Â 

Â Â Â Â Â Â Â Â Â Â Â Â CaseÂ Study:Â DiffÂ ViewerÂ 

Â 

Â Â Â Â Â Â Â Â Â Â Â Â CaseÂ Study:Â MobileÂ AppÂ ClientÂ inÂ iOSÂ 

Â 

Â Â Â Â Â Â Â Â Â Â Â Â CaseÂ Study:Â GitÂ RepoÂ ExplorerÂ withÂ BranchÂ DiffÂ ViewingÂ 

**Â **

**ImplicationsÂ andÂ RecommendationsÂ **

**Â **

**ReferencesÂ **

Â 

Â 

Â 

**Â **

2Â 

Â 

</div>

<span id="4"></span>

<div id="page4-div"
style="position:relative;width:918px;height:1188px;">

**IntroductionÂ   
TheÂ CurrentÂ StateÂ ofÂ AIÂ CodingÂ **

TodayÊ¼sÂ AIÂ codingÂ assistantsÂ primarilyÂ operateÂ inÂ whatÂ weÂ termÂ theÂ â€œvibeÂ codingË®Â   
modelâ€”chat-styleÂ interactionsÂ thatÂ provideÂ codeÂ suggestions,Â explanations,Â orÂ simpleÂ fixesÂ   
basedÂ onÂ immediateÂ context.Â WhileÂ aÂ majorÂ improvementÂ overÂ "autocomplete"Â toolsÂ ofÂ theÂ   
pastÂ andÂ veryÂ usefulÂ forÂ basicÂ tasks,Â theseÂ toolsÂ struggleÂ with:Â 

â—Â 

anchoring:Â limitedÂ abilityÂ toÂ maintainÂ coherencyÂ andÂ focusÂ onÂ largerÂ tasksÂ 

â—Â 

refinement:Â systematicÂ improvementÂ isÂ patchyÂ andÂ edge-caseÂ handing,Â unevenÂ 

â—Â 

completion:Â successÂ statesÂ areÂ open-endedÂ andÂ requireÂ humanÂ instructionÂ 

â—Â 

complexity:Â weakÂ abilityÂ toÂ systematicallyÂ approachÂ multi-facetedÂ problemsÂ 

**Â **

**TheÂ PromiseÂ ofÂ AutonomousÂ ProgrammingÂ **

TheÂ nextÂ evolutionÂ inÂ AI-assistedÂ softwareÂ developmentÂ requiresÂ systemsÂ thatÂ canÂ maintainÂ   
coherency,Â orÂ atÂ leastÂ focusÂ acrossÂ extendedÂ developmentÂ sessionsÂ asÂ wellÂ asÂ   
systematicallyÂ iterateÂ andÂ improveÂ implementationsÂ inÂ non-trivialÂ casesÂ withoutÂ humanÂ   
supervision.Â TheyÂ mustÂ provideÂ built-inÂ qualityÂ assuranceÂ throughÂ structuredÂ automatedÂ   
validationÂ andÂ beÂ ableÂ toÂ handleÂ complex,Â multi-stepÂ developmentÂ tasksÂ withoutÂ   
interruptingÂ aÂ flowÂ regularlyÂ forÂ humanÂ instruction.Â 

WeÂ expectÂ autonomousÂ iterationÂ turnsÂ toÂ expandÂ fromÂ aÂ medianÂ ofÂ 5mÂ toÂ 30î‚ˆ60m.Â ThisÂ isÂ   
basedÂ onÂ aÂ simpleÂ extrapolationÂ ofÂ automatingÂ aÂ roughÂ averageÂ ofÂ 10Â agenticÂ turns,Â eachÂ ofÂ   
5mÂ inÂ length.Â OurÂ observationÂ isÂ thatÂ humansÂ areÂ ableÂ toÂ completeÂ chunkyÂ programmingÂ   
tasksÂ viaÂ vibeÂ codingÂ inÂ fewerÂ turnsÂ thanÂ thisÂ andÂ theÂ goalÂ wouldÂ beÂ forÂ autocodingÂ toÂ   
clearlyÂ exceedÂ thisÂ median.Â 

Â 

Â 

Â 

Â 

**Â **

3Â 

Â 

</div>

<span id="5"></span>

<div id="page5-div"
style="position:relative;width:918px;height:1188px;">

**AdversarialÂ CooperationÂ   
**AutocodingÂ isÂ basedÂ onÂ aÂ closeÂ readingÂ ofÂ vibe-codingÂ itselfÂ asÂ aÂ dialecticalÂ reasoningÂ   
process:Â arrivingÂ atÂ aÂ satisfactoryÂ solutionÂ throughÂ theÂ exchangeÂ ofÂ instructionsÂ andÂ   
correspondingÂ progressÂ reports.Â InÂ ourÂ implementation,Â g3,Â thisÂ manifestsÂ asÂ aÂ structuredÂ   
dialogueÂ betweenÂ twoÂ specializedÂ programmingÂ agents:Â 

AÂ **player**Â agentÂ thatÂ focusesÂ onÂ implementation,Â creativity,Â andÂ problem-solving,Â 

â—Â 

ReadsÂ requirementsÂ andÂ implementsÂ aÂ solutionÂ 

â—Â 

WritesÂ code,Â createsÂ harnesses,Â andÂ executesÂ commandsÂ 

â—Â 

RespondsÂ toÂ specificÂ feedbackÂ withÂ targetedÂ improvementsÂ 

â—Â 

OptimizedÂ forÂ codeÂ productionÂ andÂ executionÂ 

AÂ **coach**Â agentÂ thatÂ focusesÂ onÂ analysis,Â critique,Â andÂ validation,Â 

â—Â 

ValidatesÂ implementationsÂ againstÂ requirementsÂ 

â—Â 

TestsÂ compilationÂ andÂ functionalityÂ 

â—Â 

ProvidesÂ specific,Â actionableÂ feedbackÂ 

â—Â 

OptimizedÂ forÂ evaluationÂ andÂ guidanceÂ 

BothÂ agentsÂ beginÂ withÂ theÂ sameÂ setÂ ofÂ goalÂ requirements:Â aÂ comprehensiveÂ page-longÂ   
documentÂ thatÂ describesÂ theÂ particularsÂ ofÂ whatÂ weÂ areÂ tryingÂ toÂ accomplish.Â TheÂ   
requirementsÂ steerÂ clearÂ ofÂ implementationÂ detailsÂ orÂ instructions,Â saveÂ certainÂ basicÂ   
guidanceÂ suchÂ asÂ choiceÂ ofÂ programmingÂ languageÂ andÂ targetÂ platform.Â WeÂ doÂ thisÂ toÂ allowÂ   
theÂ autocodingÂ processÂ maximumÂ flexibilityÂ inÂ arrivingÂ atÂ itsÂ solution.Â 

TheÂ adversarialÂ processÂ itselfÂ operatesÂ withinÂ carefullyÂ definedÂ bounds:Â 

â—Â 

**turnÂ limits**:Â maximumÂ numberÂ ofÂ turnsÂ betweenÂ playerÂ andÂ coachÂ (typicallyÂ 10î‚‚Â 

â—Â 

**contextÂ windows:**Â eachÂ turnÂ startsÂ withÂ freshÂ agentsÂ toÂ preventÂ contextÂ pollutionÂ 

â—Â 

**requirements**:Â sharedÂ requirementsÂ docÂ providesÂ consistentÂ evaluationÂ criteriaÂ 

â—Â 

**approvalÂ gates:Â **explicitÂ approvalÂ fromÂ theÂ coachÂ terminatesÂ successfulÂ runsÂ 

Â 

Â 

Â 

**Â **

4Â 

Â 

</div>

<span id="6"></span>

<div id="page6-div"
style="position:relative;width:918px;height:1188px;">

None

TheÂ followingÂ snippetÂ demonstratesÂ autonomouslyÂ generatedÂ reviewÂ feedbackÂ fromÂ theÂ   
coachÂ agentÂ toÂ theÂ player'sÂ subsequentÂ turn,Â forÂ anÂ emailÂ clientÂ application:Â 

\*\*REQUIREMENTSÂ COMPLIANCE:\*\*Â   
-Â 

âœ…Â RustÂ backendÂ withÂ Actix-webÂ frameworkÂ 

-Â 

âœ…Â TypeScriptÂ frontendÂ structureÂ existsÂ 

-Â 

âœ…Â SQLiteÂ databaseÂ withÂ properÂ schemaÂ 

-Â 

âœ…Â JWTÂ authenticationÂ frameworkÂ 

-Â 

âœ…Â EmailÂ protocolÂ supportÂ (IMAP/SMTP)Â 

-Â 

âœ…Â RESTÂ APIÂ endpointsÂ definedÂ 

-Â 

âŒÂ FrontendÂ buildÂ systemÂ notÂ functionalÂ 

-Â 

âŒÂ MissingÂ criticalÂ modelÂ definitionsÂ 

-Â 

âŒÂ IncompleteÂ authenticationÂ middlewareÂ 

Â   
**\*\*IMMEDIATEÂ ACTIONSÂ NEEDED:\*\*Â   
1.Â ImplementÂ missingÂ UserÂ modelÂ andÂ otherÂ coreÂ modelsÂ   
2.Â CompleteÂ authenticationÂ middlewareÂ implementationÂ   
3.Â ResolveÂ frontendÂ dependencyÂ installationÂ   
4.Â ImplementÂ missingÂ serviceÂ methodsÂ   
5.Â AddÂ properÂ errorÂ handlingÂ forÂ databaseÂ operationsÂ   
**Â   
TheÂ projectÂ structureÂ isÂ well-organizedÂ andÂ followsÂ theÂ requirements,Â butÂ severalÂ criticalÂ   
componentsÂ needÂ completionÂ beforeÂ theÂ systemÂ canÂ functionÂ properly.Â   
Â 

Â 

ThisÂ providesÂ aÂ senseÂ ofÂ theÂ progressÂ beingÂ madeÂ whileÂ alsoÂ highlightingÂ theÂ deltaÂ toÂ   
completion.Â FurtherÂ toÂ this,Â concise,Â actionableÂ feedbackÂ allowsÂ theÂ nextÂ playerÂ turnÂ toÂ beÂ   
focusedÂ onÂ theÂ mattersÂ neededÂ toÂ bridgeÂ theÂ delta.Â 

Â 

Â 

Â 

Â 

**Â   
Â   
**Â 

Â 

Â 

**Â **

5Â 

Â 

</div>

<span id="7"></span>

<div id="page7-div"
style="position:relative;width:918px;height:1188px;">

Rust

**ContextÂ WindowÂ ManagementÂ   
**OneÂ ofÂ theÂ surprisingÂ benefitsÂ ofÂ autocodingÂ isÂ howÂ itÂ addressesÂ contextÂ windowÂ   
limitations.Â InÂ theÂ traditionalÂ approachÂ aÂ singleÂ agentÂ accumulatesÂ contextÂ untilÂ hittingÂ limits.Â   
WithÂ theÂ adversarialÂ approach,Â however,Â aÂ freshÂ agentÂ instanceÂ accruesÂ toÂ eachÂ role,Â everyÂ   
turn,Â allowingÂ eachÂ agentÂ toÂ startÂ anewÂ butÂ withÂ dynamicÂ guidanceÂ regardingÂ areasÂ toÂ focusÂ   
on.Â 

Â 

//Â CoachÂ agentÂ beginsÂ withÂ aÂ newÂ contextÂ forÂ eachÂ reviewÂ   
letÂ coach_agentÂ =Â Agent::new_autonomous().await?;Â   
Â   
//Â PlayerÂ agentÂ isÂ givenÂ focusedÂ feedbackÂ forÂ eachÂ turnÂ   
letÂ player_promptÂ =Â format!(Â   
"AddressÂ theÂ followingÂ specificÂ feedbackÂ fromÂ theÂ coach:Â {}Â   
Â   
Context:Â YouÂ areÂ improvingÂ anÂ implementationÂ basedÂ onÂ theseÂ requirements:Â {}",Â coach_feedback,Â   
requirements);Â 

Â   
ThisÂ approachÂ allowsÂ theÂ agentÂ dyadÂ toÂ maintainÂ andÂ increase:Â 

â—Â 

**focus**:Â eachÂ agentÂ optimizesÂ forÂ itsÂ roleÂ andÂ forÂ theÂ conditionsÂ ofÂ thatÂ turnÂ 

â—Â 

**objectivity**:Â coachÂ reviewsÂ withÂ freshÂ perspectiveÂ eachÂ turnÂ 

â—Â 

**clarity**:Â eachÂ turnÂ theÂ agentsÂ beginÂ anew,Â avoidingÂ contextÂ pollutionÂ 

â—Â 

**scale**:Â theÂ systemÂ isÂ ableÂ toÂ handleÂ complexÂ tasksÂ byÂ decomposingÂ themÂ 

â—Â 

**autonomy**:Â pushÂ theÂ agentÂ loopÂ farÂ longerÂ thanÂ theÂ typicalÂ î‚£5mÂ turns,Â toÂ severalÂ   
hoursÂ 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

Â 

**Â **

6Â 

Â 

</div>

<span id="8"></span>

<div id="page8-div"
style="position:relative;width:918px;height:1188px;">

**ModelÂ UtilizationÂ   
**AnÂ additionalÂ benefitÂ inÂ thisÂ frameworkÂ isÂ thatÂ thereÂ isÂ aÂ naturalÂ pointÂ toÂ switchÂ modelsÂ orÂ Â   
providersÂ toÂ makeÂ useÂ ofÂ aÂ diversityÂ ofÂ pre-trainedÂ knowledgeÂ whichÂ haveÂ differentÂ benefitsÂ   
andÂ biasesÂ andÂ strengths.Â TheseÂ couldÂ beÂ twoÂ constantÂ butÂ differentÂ models,Â orÂ aÂ rotationÂ   
throughÂ modesÂ toÂ giveÂ differentÂ â€œplayerË®Â agentsÂ aÂ chanceÂ toÂ contributeÂ aÂ solution.Â MultipleÂ   
modelsÂ haveÂ beenÂ shownÂ toÂ assistÂ inÂ allowingÂ agentsÂ toÂ convergeÂ onÂ correctÂ solutionsÂ byÂ   
havingÂ aÂ secondÂ option,Â agentsÂ thatÂ useÂ multipleÂ modelsÂ oftenÂ leadÂ benchmarksÂ forÂ devÂ   
tasksÂ suchÂ asÂ [tbench.](https://www.tbench.ai/leaderboard/terminal-bench/2.0)2Â 

SomeÂ ofÂ theÂ leadingÂ non-adversarialÂ autocodingÂ frameworksÂ canÂ oftenÂ makeÂ useÂ ofÂ modelsÂ   
atÂ differentÂ points,Â butÂ theyÂ haveÂ toÂ beÂ insertedÂ orÂ switchedÂ to,Â orÂ consultedÂ asÂ aÂ toolÂ orÂ   
oracleÂ forÂ adviceÂ dependingÂ onÂ theÂ mainÂ agentÂ loop,Â whileÂ thisÂ isÂ aÂ naturalÂ partÂ ofÂ   
autocoding.Â 

Â   
**AutocodingÂ vsÂ Single-TurnÂ "VibeÂ **

**Coding"Â   
**TheÂ establishmentÂ ofÂ theÂ requirementsÂ contractÂ atÂ theÂ startÂ ofÂ anÂ autocodingÂ loopÂ isÂ theÂ keyÂ   
toÂ itsÂ success.Â WhileÂ individualÂ turnsÂ mayÂ veerÂ offÂ courseÂ orÂ focusÂ onÂ specificÂ issuesÂ (bugs,Â   
compileÂ failures,Â errors,Â toolÂ useÂ complications),Â theÂ repeatedÂ returnÂ toÂ theÂ originalÂ   
requirementsÂ enforcedÂ byÂ theÂ coach-playerÂ dyadÂ ensuresÂ thatÂ g3Â **alwaysÂ makesÂ progress**Â   
towardsÂ itsÂ goal.Â 

Furthermore,Â ifÂ itÂ runsÂ outÂ ofÂ turnsÂ withoutÂ aÂ satisfactoryÂ solution,Â thenÂ theÂ taskÂ isÂ typicallyÂ   
tooÂ complexÂ forÂ theÂ adversarialÂ cooperationÂ loopÂ andÂ lessÂ aÂ concernÂ aboutÂ whetherÂ orÂ notÂ   
theÂ agentÂ wasÂ capableÂ ofÂ theÂ taskÂ butÂ simplyÂ didÂ notÂ satisfyÂ itÂ forÂ otherÂ reasonsÂ (contextÂ   
windowÂ limits,Â attentionÂ issues,Â modelÂ dysfunction,Â orÂ human-in-the-loopÂ problems).Â 

Turn-takingÂ vibeÂ codingÂ alsoÂ hasÂ theÂ followingÂ disadvantagesÂ thatÂ adversarialÂ autocodingÂ   
overcomesÂ byÂ itsÂ design,Â 

â—Â 

itÂ isÂ aÂ time-intensiveÂ processÂ asÂ agentsÂ waitÂ forÂ humanÂ reviewÂ 

â—Â 

humansÂ mustÂ beÂ presentÂ whenÂ theÂ agentÂ turnÂ completesÂ forÂ efficientÂ loopÂ   
progressionÂ 

â—Â 

schedulingÂ constraints:Â aiÂ agentsÂ lieÂ idleÂ onÂ nightsÂ andÂ weekendsÂ whenÂ humansÂ   
typicallyÂ doÂ notÂ work,Â whileÂ autonomousÂ agentsÂ canÂ runÂ continuouslyÂ 

â—Â 

inconsistentÂ reviewÂ qualityÂ 

â—Â 

FrequentÂ contextÂ switchingÂ costÂ forÂ supervisingÂ humans3Â Â 

**Â   
**Â 

3Â [https://dl.acm.org/doi/10.1145/1281700.1281702Â ](https://dl.acm.org/doi/10.1145/1281700.1281702)Â 

2Â <https://www.tbench.ai/leaderboard/terminal-bench/2.0>Â 

Â 

Â 

**Â **

7Â 

Â 

</div>

<span id="9"></span>

<div id="page9-div"
style="position:relative;width:918px;height:1188px;">

None

**EmpiricalÂ ResultsÂ andÂ CaseÂ StudiesÂ   
Â **

**CaseÂ Study:Â CalculatorÂ APIÂ **

InÂ theÂ degenerateÂ caseÂ ofÂ anÂ applicationÂ toÂ performÂ basicÂ arithmeticÂ operations,Â weÂ findÂ   
thatÂ g3Â alreadyÂ demonstratesÂ theÂ strengthsÂ ofÂ adversarialÂ cooperation.Â 

**gooseÂ   
**Â 

\##Â TestingÂ &Â QualityÂ   
**-Â \[Â \]Â WriteÂ unitÂ testsÂ forÂ allÂ operationsÂ   
-Â \[Â \]Â WriteÂ integrationÂ testsÂ forÂ APIÂ endpointsÂ   
-Â \[Â \]Â TestÂ errorÂ casesÂ andÂ edgeÂ conditionsÂ   
-Â \[Â \]Â ValidateÂ determinismÂ andÂ reproducibilityÂ   
**Â   
\##Â ConfigurationÂ &Â DeploymentÂ   
-Â \[x\]Â EnvironmentÂ variableÂ configurationÂ   
-Â \[x\]Â LoggingÂ andÂ metricsÂ setupÂ   
**-Â \[Â \]Â DockerÂ setupÂ   
-Â \[Â \]Â DocumentationÂ (README)**Â 

Â   
gooseÂ isÂ ableÂ toÂ makeÂ someÂ progressÂ andÂ implementÂ severalÂ ofÂ theÂ basicÂ featuresÂ butÂ itÂ   
failsÂ beforeÂ fullyÂ achievingÂ theÂ requirementsÂ laidÂ out.Â ThisÂ isÂ despiteÂ theÂ factÂ thatÂ gooseÂ hasÂ   
theÂ abilityÂ toÂ triggerÂ subagentsÂ toÂ workÂ aroundÂ contextÂ windowÂ limitationsÂ andÂ mimicsÂ theÂ   
taskÂ decompositionÂ andÂ focusÂ assignmentÂ necessaryÂ forÂ complexÂ workflows.Â 

**autocodingÂ withÂ g3Â   
**Â   
g3Â onÂ theÂ otherÂ handÂ isÂ ableÂ toÂ completeÂ theÂ requirementsÂ inÂ aÂ fewÂ turns.Â ThisÂ isÂ notÂ   
becauseÂ ofÂ anyÂ fundamentalÂ improvementÂ toÂ theÂ underlyingÂ codingÂ capability,Â ratherÂ itÂ isÂ   
theÂ frameworkÂ ofÂ dialecticalÂ reasoningÂ thatÂ allowsÂ theÂ systemÂ dyadÂ toÂ overcomeÂ   
shortcomingsÂ inÂ agentÂ codingÂ capabilitiesÂ withÂ adversarialÂ design.Â 

AgentsÂ oftenÂ elideÂ instructionsÂ inÂ longerÂ prompts.Â ForÂ regularÂ usersÂ ofÂ AIÂ codingÂ assistants,Â   
thisÂ kindÂ ofÂ oversightÂ isÂ allÂ tooÂ common:Â 

**\*\*MissingÂ HTTPSÂ enforcement\*\***Â -Â RequirementsÂ mandateÂ "AllÂ communicationÂ   
overÂ HTTPS"Â butÂ noÂ HTTPSÂ redirectÂ middlewareÂ isÂ implementedÂ 

Â   
InÂ theÂ vibeÂ codingÂ framework,Â aÂ humanÂ wouldÂ haveÂ toÂ noticeÂ thisÂ gapÂ andÂ instructÂ theÂ agentÂ   
toÂ resolveÂ it,Â howeverÂ withÂ adversarialÂ autocodingÂ theÂ deficiencyÂ isÂ noticedÂ andÂ patchedÂ   
automatically.Â Â 

Further,Â evenÂ whileÂ autocoding,Â theÂ implementingÂ agentÂ oftenÂ declaresÂ withÂ tooÂ muchÂ   
confidenceÂ thatÂ itÂ hasÂ satisfiedÂ theÂ taskÂ whichÂ theÂ adversarialÂ designÂ catchesÂ nicely:Â   
Â 

Â 

**Â **

8Â 

Â 

</div>

<span id="10"></span>

<div id="page10-div"
style="position:relative;width:918px;height:1188px;">

Shell

Shell

Â 

IÂ haveÂ successfullyÂ implementedÂ aÂ completeÂ CalculatorÂ APIÂ accordingÂ toÂ allÂ theÂ   
specifiedÂ requirements.Â Here'sÂ whatÂ wasÂ delivered:Â   
Â   
ğŸ¯Â CoreÂ FeaturesÂ ImplementedÂ   
Â   
ArithmeticÂ OperationsÂ   
-Â 

âœ…Â 8Â Operations:Â add,Â sub,Â mul,Â div,Â pow,Â sqrt,Â neg,Â absÂ 

-Â 

âœ…Â DecimalÂ Precision:Â UsesÂ Decimal.jsÂ forÂ deterministicÂ decimalÂ arithmeticÂ 

-Â 

âœ…Â ConfigurableÂ Scale:Â CustomÂ decimalÂ placesÂ andÂ roundingÂ modesÂ 

-Â 

âœ…Â InputÂ Validation:Â StringÂ operandsÂ withÂ properÂ validationÂ 

Â   
This,Â despiteÂ theÂ aforementionedÂ HTTPSÂ bugÂ thatÂ wasÂ detectedÂ byÂ theÂ coachÂ agent,Â alongÂ   
withÂ severalÂ otherÂ gapsÂ toÂ theÂ originalÂ requirements.Â HumansÂ areÂ wontÂ toÂ believeÂ theÂ agentÂ   
whenÂ itÂ declaresÂ successÂ whileÂ theÂ coachÂ isÂ rigidlyÂ adherentÂ toÂ originalÂ requirements.Â Â 

HereÂ isÂ anotherÂ exampleÂ whereÂ theÂ coachÂ agentÂ providesÂ guidanceÂ toÂ refocusÂ theÂ attentionÂ   
ofÂ theÂ systemÂ dyad:Â 

\*\*IssuesÂ Found:\*\*Â   
Â   
1.Â \*\*MissingÂ roundingÂ modeÂ implementation\*\*Â -Â TheÂ \`/v1/calc/expr\`Â endpointÂ acceptsÂ   
aÂ \`rounding\`Â parameterÂ butÂ doesn'tÂ useÂ itÂ (markedÂ asÂ TODOÂ inÂ routes.js)Â   
Â   
2.Â \*\*AuthenticationÂ notÂ enforcedÂ forÂ health/versionÂ endpoints\*\*Â -Â RequirementsÂ   
specifyÂ "AuthenticationÂ requiredÂ viaÂ bearerÂ token"Â butÂ \`/v1/healthz\`Â andÂ   
\`/v1/version\`Â endpointsÂ bypassÂ authenticationÂ middlewareÂ   
Â   
3.Â \*\*MissingÂ HTTPSÂ enforcement\*\*Â -Â RequirementsÂ mandateÂ "AllÂ communicationÂ overÂ   
HTTPS"Â butÂ noÂ HTTPSÂ redirectÂ middlewareÂ isÂ implementedÂ   
Â   
4.Â \*\*IncompleteÂ metrics/observability\*\*Â -Â RequirementsÂ specifyÂ metricsÂ forÂ requestÂ   
count,Â latency,Â errorÂ countÂ butÂ noÂ metricsÂ collectionÂ endpointÂ orÂ middlewareÂ isÂ   
implementedÂ   
Â   
5.Â \*\*MissingÂ readiness/livenessÂ checks\*\*Â -Â RequirementsÂ specifyÂ theseÂ mustÂ beÂ   
availableÂ butÂ onlyÂ basicÂ healthÂ checkÂ existsÂ   
6.Â \*\*PackageÂ installationÂ blocked\*\*Â -Â CannotÂ verifyÂ fullÂ compilationÂ dueÂ toÂ   
networkÂ restrictions,Â butÂ syntaxÂ validationÂ passesÂ   
Â   
**\*\*SpecificÂ fixesÂ needed:\*\*Â   
-Â ImplementÂ roundingÂ modeÂ handlingÂ inÂ expressionÂ evaluatorÂ   
-Â AddÂ authenticationÂ toÂ health/versionÂ endpointsÂ orÂ documentÂ exemptionÂ   
-Â AddÂ HTTPSÂ enforcementÂ middlewareÂ   
-Â ImplementÂ metricsÂ collectionÂ andÂ \`/metrics\`Â endpointÂ   
-Â AddÂ separateÂ readiness/livenessÂ endpointsÂ   
-Â ConsiderÂ addingÂ inputÂ sanitizationÂ beyondÂ validationÂ **

Â 

Â 

**Â **

9Â 

Â 

</div>

<span id="11"></span>

<div id="page11-div"
style="position:relative;width:918px;height:1188px;">

None

Â   
TheÂ keyÂ insightÂ inÂ theÂ adversarialÂ dyadÂ isÂ toÂ discardÂ theÂ implementingÂ agent'sÂ self-reportÂ ofÂ   
successÂ andÂ haveÂ theÂ coachÂ performÂ anÂ independentÂ evaluationÂ ofÂ complianceÂ toÂ   
requirements.Â Â 

WhenÂ theÂ coachÂ approvesÂ anÂ implementation,Â itÂ isÂ farÂ moreÂ thoroughÂ andÂ oftenÂ   
outperformsÂ human-agentÂ supervision,Â particularlyÂ forÂ edge-caseÂ detectionÂ andÂ   
completeness:Â 

Â 

ğŸ“ŠÂ ValidationÂ ResultsÂ   
Â   
ErrorÂ HandlingÂ   
âœ…Â DivisionÂ byÂ zero:Â {"error":{"code":"DIVISION_BY_ZERO","message":"DivisionÂ byÂ zero"}}Â 

âœ…Â NegativeÂ sqrt:Â {"error":{"code":"NEGATIVE_SQRT","message":"SquareÂ rootÂ ofÂ negativeÂ number"}}Â 

âœ…Â UnauthorizedÂ access:Â {"error":{"code":"UNAUTHORIZED","message":"Unauthorized"}}Â   
Â   
AuthenticationÂ TestingÂ   
âœ…Â CorrectÂ BearerÂ token:Â AuthenticationÂ successfulÂ 

âœ…Â WrongÂ BearerÂ token:Â ProperlyÂ rejectedÂ (401Â Unauthorized)Â 

âœ…Â MissingÂ AuthorizationÂ header:Â ProperlyÂ rejectedÂ (401Â Unauthorized)Â 

âœ…Â MalformedÂ AuthorizationÂ header:Â ProperlyÂ rejectedÂ (401Â Unauthorized)Â   
Â   
AdvancedÂ FeaturesÂ   
âœ…Â BatchÂ operations:Â MixedÂ success/errorÂ handlingÂ 

âœ…Â ExpressionÂ evaluation:Â {"result":"14.00"}Â (2Â +Â 3Â \*Â 4)Â 

âœ…Â HealthÂ endpoint:Â {"status":"ok"}Â 

âœ…Â VersionÂ endpoint:Â CompleteÂ buildÂ informationÂ 

âœ…Â TLSÂ configuration:Â CertificateÂ validationÂ workingÂ   
Â   
ğŸ¯**Â FinalÂ Status:Â COACHÂ APPROVEDÂ **

Â   
InÂ thisÂ way,Â wholeÂ classesÂ ofÂ problemsÂ extantÂ inÂ programmingÂ withÂ AIÂ agentsÂ areÂ greatlyÂ   
minimizedÂ ifÂ notÂ completelyÂ absentÂ inÂ adversarialÂ autocoding.Â 

**Â **

Â 

Â 

Â 

Â 

Â 

Â 

Â 

**Â **

10Â 

Â 

</div>

<span id="12"></span>

<div id="page12-div"
style="position:relative;width:918px;height:1188px;">

**CaseÂ Study:Â DiffÂ ViewerÂ **

Â 

ThisÂ application4Â isÂ aÂ visualÂ diffÂ (desktopÂ app)Â builtÂ byÂ g3Â fromÂ aÂ simpleÂ requirementÂ ofÂ   
â€œprovideÂ aÂ beforeÂ andÂ afterÂ diffÂ viewÂ ofÂ aÂ highlyÂ visualÂ explorerÂ ofÂ aÂ gitÂ repositoryÂ withÂ aÂ   
timelineË®,Â andÂ wasÂ ableÂ toÂ yieldÂ aÂ nativeÂ (swiftUIî‚‚Â applicationÂ afterÂ 4Â coach/playerÂ turns.Â Â 

Â 

Â   
PriorÂ attemptsÂ toÂ deliverÂ thisÂ applicationÂ viaÂ claude-codeÂ andÂ gooseÂ fellÂ shortÂ ofÂ completeÂ   
andÂ usableÂ resultsÂ withoutÂ furtherÂ humanÂ instruction.Â 

**Â **

Â 

**Â **

Â 

Â 

4[Â https://github.com/michaelneale/swifty-diff](https://github.com/michaelneale/swifty-diff)Â   
Â 

Â 

**Â **

11Â 

Â 

</div>

<span id="13"></span>

<div id="page13-div"
style="position:relative;width:918px;height:1188px;">

**Â **

**CaseÂ Study:Â MobileÂ AppÂ ClientÂ inÂ iOSÂ **

TheÂ gooseÂ agentÂ hasÂ aÂ desktopÂ componentÂ whichÂ   
runsÂ aÂ serverÂ (daemon)Â whichÂ canÂ beÂ accessedÂ   
remotely.Â InÂ thisÂ caseÂ theÂ g3Â projectÂ wasÂ usedÂ toÂ   
initiateÂ andÂ createÂ aÂ clientÂ iOSÂ application5Â basedÂ   
onÂ theÂ APIÂ specificationsÂ andÂ requirementsÂ forÂ   
chatÂ basedÂ interactions.Â 

SimilarÂ toÂ theÂ diffÂ application,Â thisÂ hadÂ follow-onÂ   
human-in-the-loopÂ interactiveÂ sessionsÂ (inÂ thisÂ   
caseÂ farÂ more)Â toÂ completeÂ theÂ features,Â andÂ   
moveÂ theÂ applicationÂ toÂ aÂ reviewableÂ state.Â OneÂ ofÂ   
theÂ weaknessesÂ thatÂ requiredÂ moreÂ interactionÂ   
(insteadÂ ofÂ drivingÂ fromÂ requirementsÂ only)Â wasÂ   
thatÂ computer-controllingÂ withÂ iOSÂ emulatorsÂ areÂ   
currentlyÂ lacking.Â WebÂ applicationÂ automationÂ andÂ   
otherÂ desktopÂ appÂ automationÂ isÂ richer,Â andÂ   
furtherÂ researchÂ isÂ neededÂ toÂ assistÂ agentsÂ inÂ   
controllingÂ emulatorÂ environmentsÂ toÂ allowÂ theÂ   
coachÂ toÂ evaluateÂ aÂ richÂ mobileÂ application.Â 

Â 

Â 

Â 

Â 

[5Â https://github.com/dhanji/goose-iosÂ ](https://github.com/dhanji/goose-ios)

Â 

Â 

Â 

**Â **

12Â 

Â 

</div>

<span id="14"></span>

<div id="page14-div"
style="position:relative;width:918px;height:1188px;">

**CaseÂ Study:Â GitÂ RepoÂ ExplorerÂ withÂ BranchÂ DiffÂ ViewingÂ **

Â   
ThisÂ wasÂ anÂ attemptÂ toÂ compareÂ theÂ performanceÂ ofÂ aÂ selectionÂ ofÂ leadingÂ codingÂ platformsÂ   
byÂ askingÂ forÂ theÂ implementationÂ ofÂ aÂ relativelyÂ simpleÂ application.Â TheÂ applicationÂ wasÂ   
non-trivial,Â butÂ simpleÂ andÂ achievableÂ enoughÂ thatÂ eachÂ platformÂ hadÂ aÂ fairÂ chanceÂ ofÂ   
success.Â AÂ terminalÂ UIÂ î‚TUIî‚‚Â wasÂ specifiedÂ forÂ easeÂ ofÂ testingÂ acrossÂ theÂ differentÂ   
platforms.Â (g3Â wasÂ elsewhereÂ testedÂ withÂ web,Â swift,Â MacOS,Â andÂ mobileÂ applications).Â 

ForÂ consistency,Â weÂ attemptedÂ toÂ testÂ theÂ platformsÂ withÂ theÂ sameÂ LLMÂ -Â   
Claude-sonnet-4î‚ˆ5Â withÂ thinkingÂ mode.Â ThisÂ wasÂ notÂ possibleÂ onÂ allÂ platformsÂ (seeÂ tableÂ   
below).Â 

Â 

g3Ê¼sÂ implementation,Â noteÂ thatÂ itÂ hasÂ theÂ side-by-sideÂ diff,Â canÂ doÂ branchÂ diffs,Â showsÂ anÂ attemptÂ atÂ commitÂ tree.Â 

Â 

InÂ aÂ one-shotÂ scenario,Â noÂ additionalÂ userÂ inputÂ wasÂ givenÂ toÂ theÂ toolÂ beyondÂ theÂ   
requirements.Â AllÂ platformsÂ generatedÂ plausibleÂ lookingÂ code.Â AfterÂ manualÂ testing,Â weÂ   
attemptedÂ toÂ promptÂ theÂ toolÂ toÂ fixÂ theÂ bugsÂ orÂ runÂ theÂ application,Â withÂ mixedÂ results.Â   
TheseÂ attemptsÂ areÂ mentionedÂ inÂ â€œimplementationÂ passesË®.Â ForÂ g3Â inÂ autonomousÂ modeÂ   
(coach/player)Â itÂ promptedÂ itself,Â requiringÂ noÂ intervention.Â OnlyÂ afterÂ aÂ fullÂ runÂ didÂ weÂ   
attemptÂ toÂ useÂ theÂ tool.Â 

NoteÂ thatÂ theÂ aimÂ ofÂ runningÂ g3Â inÂ coach+playerÂ modeÂ isÂ toÂ achieveÂ autonomousÂ coding.Â   
ThusÂ emphasisÂ isÂ onÂ one-shotÂ implementationÂ withÂ no,Â orÂ absolutelyÂ minimalÂ userÂ   
interaction,Â andÂ runningÂ timeÂ isÂ veryÂ muchÂ aÂ secondaryÂ consideration.Â 

Â 

Â 

**Â **

13Â 

Â 

</div>

<span id="15"></span>

<div id="page15-div"
style="position:relative;width:918px;height:1188px;">

ForÂ noneÂ ofÂ theÂ testsÂ didÂ weÂ spendÂ extensiveÂ timeÂ tryingÂ toÂ debugÂ aÂ crashingÂ application.Â   
WeÂ attemptedÂ toÂ getÂ theÂ platformÂ toÂ self-diagnoseÂ ifÂ possible,Â andÂ whereÂ thatÂ didnÊ¼tÂ work,Â   
gaveÂ aÂ stackÂ traceÂ orÂ explainedÂ theÂ problem.Â ThatÂ wasÂ onlyÂ attemptedÂ aÂ maximumÂ ofÂ 3Â   
timesÂ beforeÂ givingÂ up.Â 

Â   
Â 

Â 

**g3Â **

**GooseÂ **

**AntigravityÂ **

**OpenHandsÂ **

**VSCodeÂ CodexÂ **

**CursorÂ ProÂ **

CompletenessÂ (/5)Â Â   
finalÂ outcomeÂ 

5/5Â Â   
MeetsÂ allÂ   
requirements.Â Â   
NoÂ crashes.Â 

4.5/5Â   
VeryÂ Functional,Â   
occasionalÂ   
crashes.Â 

3/5Â   
InitiallyÂ crashedÂ   
atÂ startup.Â WithÂ   
prompting,Â itÂ   
fixedÂ that,Â butÂ   
stillÂ crashesÂ   
occasionally.Â 

2/5Â   
Incomplete,Â   
wonâ€™tÂ loadÂ   
branches.Â 

1/5Â   
CrashesÂ onÂ start.Â   
Couldnâ€™tÂ fixÂ itÂ   
afterÂ someÂ   
prompting.Â 

1.5/5Â   
UnableÂ toÂ loadÂ   
repo.Â AfterÂ   
promptingÂ itÂ   
attemptsÂ to,Â butÂ   
crashes.Â 

ModelÂ 

Claude-sonnet-4-5Â   
withÂ thinkingÂ 

Claude-sonnet-4-5Â 

Claude-sonnet-4-5Â   
withÂ thinkingÂ 

ClaudeÂ 3.5Â SonnetÂ 

GPT-5.1-Codex-MaxÂ 

Claude-sonnet-4-5Â   
withÂ thinkingÂ 

ObservationsÂ aboutÂ   
theÂ implementationÂ 

MeetsÂ allÂ theÂ   
requirements,Â   
(visuallyÂ notÂ theÂ   
mostÂ attractive).Â   
Â 

MeetsÂ allÂ theÂ   
requirements,Â   
butÂ hasÂ oneÂ orÂ   
twoÂ bugsÂ thatÂ   
causeÂ itÂ toÂ crashÂ   
occasionallyÂ   
(visuallyÂ notÂ theÂ   
mostÂ attractive)Â 

HasÂ goodÂ UI,Â   
showsÂ commitÂ   
historyÂ   
separately.Â   
NoÂ side-by-sideÂ   
diff.Â Â   
NoÂ focusÂ cursor.Â   
NoÂ branchÂ diff.Â   
OccasionalÂ   
crashes.Â 

DecentÂ UI,Â butÂ   
wonâ€™tÂ loadÂ   
branches.Â 

NotÂ workingÂ atÂ   
all.Â AÂ bunchÂ ofÂ   
codeÂ hasÂ â€˜passâ€™Â   
inÂ it.Â LooksÂ   
poorlyÂ done.Â 

UIÂ suggestsÂ itÂ   
mightÂ showÂ theÂ   
thingsÂ weÂ askedÂ   
for,Â butÂ itÂ doesnâ€™tÂ   
work.Â 

ObservationÂ aboutÂ   
theÂ processÂ &Â   
platform.Â 

RanÂ inÂ   
autonomousÂ   
modeÂ withÂ noÂ   
userÂ interaction.Â   
TookÂ aÂ longÂ timeÂ   
toÂ run.Â   
UnpolishedÂ UI.Â 

RanÂ theÂ fastest.Â   
NoÂ userÂ   
interaction.Â Â   
GoodÂ levelÂ ofÂ   
userÂ feedback.Â 

VeryÂ goodÂ userÂ   
feedbackÂ inÂ theÂ   
UI,Â alsoÂ fast.Â   
GoodÂ promptsÂ toÂ   
confirmÂ promptÂ   
refinementÂ andÂ   
permissions.Â   
GreatÂ atÂ   
controllingÂ theÂ   
appÂ viaÂ   
keystrokesÂ etc..Â   
(neededÂ explicitÂ   
prompting)Â 

GoodÂ levelÂ ofÂ   
userÂ feedback.Â   
Â   
IÂ couldnâ€™tÂ   
upgradeÂ theÂ   
model.Â   
TheÂ testÂ ofÂ theÂ   
appÂ keptÂ hangingÂ   
(noÂ goodÂ supportÂ   
forÂ killingÂ   
process)Â 

DecentÂ levelÂ ofÂ   
userÂ feedbackÂ inÂ   
theÂ UI.Â 

GoodÂ userÂ   
feedbackÂ inÂ theÂ   
UI.Â Â 

ImplementationÂ   
passesÂ 

5Â (autonomous)Â 

1Â 

2Â (manualÂ   
promptsÂ toÂ fixÂ   
things)Â 

2Â (manualÂ   
promptsÂ toÂ fixÂ   
things)Â 

2Â (futileÂ effortsÂ toÂ   
getÂ itÂ toÂ testÂ theÂ   
app)Â 

3Â (manualÂ   
promptsÂ toÂ fixÂ   
things)Â 

AutomaticallyÂ   
checkedÂ andÂ verifiedÂ   
testÂ coverageÂ 

yesÂ 

yesÂ 

yesÂ 

yesÂ 

noÂ 

yesÂ 

LOCÂ (inclÂ tests)Â 

1.8kÂ 

1kÂ 

1.4kÂ 

1.5kÂ 

1kÂ 

1.8kÂ 

Â   
Â 

Â 

Â 

**Â **

14Â 

Â 

</div>

<span id="16"></span>

<div id="page16-div"
style="position:relative;width:918px;height:1188px;">

Â 

ImplementationÂ viaÂ Antigravity.Â NoteÂ noÂ side-by-sideÂ diff,Â canÊ¼tÂ doÂ branchÂ diffs,Â butÂ hasÂ commitÂ listing.Â 

Â   
TimeÂ toÂ completionÂ variedÂ considerably.Â SomeÂ runsÂ involvedÂ unattendedÂ promptsÂ thatÂ wereÂ   
blockedÂ forÂ anÂ unknownÂ amountÂ ofÂ time,Â soÂ weÂ donÊ¼tÂ haveÂ anÂ accurateÂ timeÂ breakdown.Â   
GooseÂ wasÂ theÂ fastestÂ atÂ aroundÂ 7Â minutes,Â andÂ g3Â tookÂ theÂ longest,Â aroundÂ 3Â hours.Â GivenÂ   
thatÂ g3Â isÂ aÂ multi-passÂ approach,Â thisÂ isÂ expected.Â (also,Â g3Â isÂ non-productionÂ code,Â   
optimizationsÂ haveÂ notÂ beenÂ attempted.Â ItÂ isÂ particularlyÂ slowÂ inÂ exploringÂ theÂ codebase,Â   
favouringÂ tokenÂ savingsÂ overÂ aggressiveÂ codeÂ dumpingÂ andÂ analysis).Â TheÂ otherÂ appsÂ   
completedÂ theÂ taskÂ approximatelyÂ betweenÂ 20Â minutesÂ andÂ anÂ hour.Â 

InÂ anÂ ablationÂ studyÂ withÂ g3,Â weÂ withheldÂ coachÂ feedback.Â TheÂ playerÂ wentÂ 4Â roundsÂ ofÂ   
implementationsÂ withÂ missingÂ feedback.Â OnÂ eachÂ iterationÂ itÂ spontaneouslyÂ foundÂ thingsÂ toÂ   
improve,Â howeverÂ theÂ finalÂ implementationÂ wasÂ non-functionalÂ (itÂ didnÊ¼tÂ promptÂ forÂ aÂ branchÂ   
toÂ read,Â andÂ withÂ explicitÂ promptingÂ toÂ fixÂ that,Â itÂ stillÂ wouldnÊ¼tÂ loadÂ theÂ gitÂ repo).Â TheÂ finalÂ   
outcomeÂ wasÂ onÂ parÂ withÂ theÂ OpenHandsÂ generatedÂ applicationÂ (i.e.Â plausibleÂ codeÂ wasÂ   
written,Â testsÂ wereÂ written,Â claimedÂ toÂ haveÂ implementedÂ andÂ testedÂ everything,Â butÂ wasÂ   
basicallyÂ notÂ functioning).Â 

NotedÂ chain-of-thoughtÂ commentsÂ inÂ theÂ g3Â logsÂ whenÂ weÂ didÂ haveÂ coachÂ feedback:Â â€œLetÂ   
meÂ checkÂ ifÂ theÂ commitÂ treeÂ displayÂ isÂ actuallyÂ testedÂ inÂ theÂ workflowÂ test.Ë®Â AndÂ â€œLetÂ meÂ doÂ   
aÂ moreÂ thoroughÂ checkÂ ofÂ whetherÂ theÂ implementationÂ actuallyÂ worksÂ asÂ required.Â LetÂ meÂ   
verifyÂ theÂ testÂ forÂ multi-fileÂ commitÂ workflowÂ moreÂ carefully.Ë®Â 

Â 

Â 

Â 

Â 

**Â **

15Â 

Â 

</div>

<span id="17"></span>

<div id="page17-div"
style="position:relative;width:918px;height:1188px;">

ProjectÂ specÂ givenÂ toÂ tool/platformÂ asÂ requirements:Â Â 

Â   
GitÂ RepositoryÂ TUIÂ ViewerÂ -Â ProjectÂ SpecificationÂ   
Â   
AÂ PythonÂ terminalÂ userÂ interfaceÂ (TUI)Â applicationÂ forÂ exploringÂ andÂ comparingÂ GitÂ repositoriesÂ withoutÂ   
modifyingÂ theÂ workingÂ directoryÂ state.Â TheÂ applicationÂ providesÂ aÂ multi-paneÂ interfaceÂ forÂ navigatingÂ repositoryÂ   
historyÂ andÂ viewingÂ changes.Â UseÂ theÂ https://github.com/Textualize/textualÂ libraryÂ forÂ UIÂ &Â rendering,Â youÂ canÂ   
useÂ gitÂ librariesÂ suchÂ asÂ (GitPython).Â NavigationÂ shouldÂ beÂ exclusivelyÂ withÂ cursorÂ keysÂ andÂ tab.Â   
Â   
TheÂ applicationÂ maintainsÂ aÂ listÂ ofÂ user-addedÂ GitÂ repositoriesÂ withÂ theÂ abilityÂ toÂ switchÂ betweenÂ themÂ viaÂ aÂ   
selectionÂ panel.Â ForÂ theÂ activelyÂ selectedÂ repository,Â usersÂ canÂ browseÂ allÂ branchesÂ (includingÂ worktreeÂ   
branches)Â andÂ theirÂ commitÂ historyÂ inÂ aÂ navigableÂ listÂ view.Â SelectingÂ aÂ commitÂ displaysÂ itsÂ changedÂ files,Â andÂ   
selectingÂ aÂ fileÂ rendersÂ aÂ side-by-sideÂ diffÂ viewÂ onÂ theÂ right-handÂ sideÂ ofÂ theÂ screen.Â AllÂ repositoryÂ   
inspectionÂ isÂ performedÂ usingÂ Git'sÂ objectÂ databaseÂ directly,Â neverÂ checkingÂ outÂ branchesÂ orÂ modifyingÂ theÂ   
workingÂ tree.Â   
Â   
BranchÂ diffÂ mode:Â   
UsersÂ canÂ selectÂ twoÂ branchesÂ toÂ compare,Â whichÂ displaysÂ aÂ listÂ ofÂ filesÂ thatÂ differÂ betweenÂ them.Â NavigatingÂ   
thisÂ fileÂ listÂ showsÂ side-by-sideÂ diffsÂ ofÂ eachÂ file'sÂ contentÂ betweenÂ theÂ twoÂ branchÂ heads.Â TheÂ interfaceÂ   
shouldÂ useÂ aÂ PythonÂ TUIÂ libraryÂ (suchÂ asÂ Textual)Â withÂ keyboardÂ navigationÂ throughout,Â maintainingÂ aÂ consistentÂ   
layoutÂ withÂ navigation/selectionÂ onÂ theÂ leftÂ andÂ diffÂ contentÂ onÂ theÂ right.Â   
AlsoÂ showÂ theÂ commitÂ historyÂ dependencyÂ treeÂ betweenÂ bothÂ branchesÂ underneathÂ theÂ side-by-sideÂ diffÂ view.Â   
Â   
TheÂ interfaceÂ usesÂ aÂ consistentÂ split-paneÂ design:Â leftÂ sideÂ containsÂ fixedÂ navigationÂ elementsÂ (repoÂ selector,Â   
branchÂ list,Â commitÂ list,Â fileÂ list),Â theÂ rightÂ sideÂ displaysÂ diffÂ contentÂ (side-by-side).Â AÂ modeÂ indicatorÂ   
showsÂ whetherÂ theÂ userÂ isÂ inÂ single-branchÂ historyÂ viewÂ orÂ branchÂ comparisonÂ mode.Â AllÂ navigationÂ usesÂ cursorÂ   
keysÂ withÂ clearÂ visualÂ focusÂ indicators.Â   
Â   
ImportantÂ forÂ evaluationÂ andÂ testing:Â   
Â   
RUNÂ theÂ applicationÂ yourselfÂ toÂ makeÂ sureÂ itÂ works.Â CarefullyÂ thinkÂ aboutÂ howÂ youÂ willÂ ensureÂ itÂ worksÂ asÂ   
intended.Â SendÂ keystrokesÂ toÂ theÂ appÂ toÂ makeÂ sureÂ youÂ canÂ navigateÂ andÂ loadÂ repos.Â   
Â   
MakeÂ sureÂ toÂ writeÂ highÂ qualityÂ code,Â andÂ haveÂ greatÂ testÂ coverageÂ forÂ yourÂ code,Â IÂ willÂ runÂ aÂ codeÂ coverageÂ   
tool.Â   
Â   
GuidelineÂ forÂ codeÂ design:Â   
-Â FunctionsÂ andÂ methodsÂ shouldÂ beÂ shortÂ -Â atÂ mostÂ 60Â lines,Â ideallyÂ wellÂ underÂ 40.Â   
-Â ClassesÂ shouldÂ beÂ modularÂ andÂ composable.Â TheyÂ mustÂ haveÂ betweenÂ 2Â andÂ 20Â methods.Â   
-Â DoÂ notÂ writeÂ deeplyÂ nestedÂ (aboveÂ 6Â levelsÂ deep)Â â€˜ifâ€™,Â â€˜matchâ€™Â orÂ â€˜caseâ€™Â statements,Â ratherÂ refactorÂ intoÂ   
separateÂ logicalÂ sectionsÂ orÂ functions.Â   
-Â CodeÂ shouldÂ beÂ writtenÂ suchÂ thatÂ itÂ isÂ maintainableÂ andÂ testable.Â   
-Â ForÂ PythonÂ codeÂ writeÂ \*ALL\*Â testÂ codeÂ intoÂ aÂ topÂ levelÂ â€˜testsâ€™Â directory.Â   
-Â EachÂ non-trivialÂ functionÂ shouldÂ haveÂ testÂ coverage.Â DOÂ NOTÂ WRITEÂ TESTSÂ FORÂ INDIVIDUALÂ FUNCTIONSÂ /Â METHODSÂ /Â   
CLASSESÂ unlessÂ theyÂ areÂ largeÂ andÂ important.Â WriteÂ testsÂ thatÂ testsÂ multipleÂ functionsÂ orÂ componentsÂ atÂ once,Â doÂ   
onlyÂ minimalÂ mocking,Â andÂ \*DON'TÂ ADDÂ TRIVIALÂ TESTSÂ THATÂ ONLYÂ CHECKÂ PARAMETER-PASSINGÂ ANDÂ THEÂ RESTÂ ISÂ MOCKEDÂ   
OUT\*.Â   
-Â WriteÂ testsÂ inÂ separateÂ files,Â whereÂ theÂ filenameÂ shouldÂ matchÂ theÂ mainÂ implementationÂ andÂ addingÂ aÂ â€œ\_testâ€Â   
suffix.Â   
Â   
GeneralÂ guidelinesÂ forÂ codeÂ design:Â   
-Â KeepÂ theÂ codeÂ asÂ simpleÂ asÂ possible,Â withÂ fewÂ ifÂ anyÂ externalÂ dependencies.Â   
-Â Don'tÂ repeatÂ functionalityÂ acrossÂ theÂ code,Â unlessÂ thereÂ isÂ veryÂ goodÂ reason.Â   
-Â KeepÂ eachÂ function/method/classÂ simple,Â avoidÂ unnecessaryÂ complexity.Â   
-Â ImplementÂ featuresÂ thatÂ youÂ actuallyÂ need,Â notÂ forÂ futureÂ potentialÂ expansion.Â DoÂ notÂ over-engineer.Â 

Â 

Â 

**Â **

16Â 

Â 

</div>

<span id="18"></span>

<div id="page18-div"
style="position:relative;width:918px;height:1188px;">

î‚TheÂ codeÂ qualityÂ partÂ isÂ probablyÂ superfluousÂ givenÂ thatÂ theÂ systemÂ promptÂ ofÂ variousÂ   
platformsÂ willÂ sayÂ similarÂ things.Â ItÂ wasÂ includedÂ here,Â however,Â inÂ anÂ attemptÂ toÂ standardizeÂ   
betweenÂ platforms).Â 

**ImplicationsÂ andÂ RecommendationsÂ   
**Â   
DialecticalÂ autocodingÂ inÂ theÂ â€œcoach/playerË®Â paradigmÂ ifÂ viewedÂ asÂ aÂ patternÂ canÂ beÂ   
replicatedÂ todayÂ withÂ almostÂ anyÂ agentÂ onÂ theÂ market.Â ThisÂ canÂ beÂ usedÂ atÂ theÂ veryÂ leastÂ asÂ   
aÂ stepÂ improvementÂ inÂ aidingÂ agentsÂ convergingÂ onÂ anÂ end-to-endÂ workingÂ solutionÂ withÂ   
lessÂ interruptions,Â andÂ perhapsÂ ifÂ implementedÂ moreÂ nativelyÂ provideÂ aÂ wayÂ toÂ scaleÂ parallelÂ   
developmentÂ allowingÂ theÂ human-in-the-loopÂ toÂ maintainÂ deeperÂ focusÂ onÂ tasksÂ whereÂ   
needed.Â WeÂ furtherÂ believeÂ thatÂ thisÂ canÂ overcomeÂ theÂ nightsÂ andÂ weekendsÂ problem,Â withÂ   
multipleÂ competingÂ pathsÂ inÂ anÂ experimentÂ clusterÂ takenÂ simultaneouslyÂ ratherÂ thanÂ havingÂ   
toÂ restrictÂ byÂ humanÂ resourceÂ availability.Â Â 

NotÂ onlyÂ doesÂ thisÂ dramaticallyÂ increaseÂ theÂ efficiencyÂ ofÂ aiÂ codingÂ toolsÂ ofÂ today,Â butÂ withÂ   
farÂ fewerÂ human-in-the-loopÂ turnsÂ required,Â opensÂ upÂ significantÂ possibilitiesÂ forÂ   
non-technicalÂ peopleÂ toÂ developÂ competentÂ software.Â 

WeÂ proposeÂ toÂ addÂ adversarialÂ cooperationÂ asÂ anÂ enhancementÂ toÂ gooseÂ inÂ theÂ nearÂ future.Â 

Â 

**ReferencesÂ andÂ NotesÂ   
**1.Â Â <https://github.com/dhanji/g3>Â Â   
2.Â [https://www.tbench.ai/leaderboard/terminal-bench/2.0Â   
](https://www.tbench.ai/leaderboard/terminal-bench/2.0)3.Â [https://dl.acm.org/doi/10.1145/1281700.1281702Â ](https://dl.acm.org/doi/10.1145/1281700.1281702)Â 

4.Â Â <https://github.com/michaelneale/swifty-diff>Â 

5.[Â Â https://github.com/dhanji/goose-iosÂ ](https://github.com/dhanji/goose-ios)Â   
Â 

Â   
Â 

Â 

**Â   
Â **

Â 

**Â   
**Â   
Â 

Â 

**Â **

17Â 

Â 

</div>

<span id="outline"></span>

# Document Outline

- [Â ](converted.html#1)
- [Adversarial Cooperation â€‹In Code SynthesisÂ ](converted.html#1)
- [A New Paradigm For AI-Assisted Software
  DevelopmentÂ ](converted.html#1)
- [AbstractÂ ](converted.html#2)
  - [Â ](converted.html#2)
- [Table of ContentsÂ ](converted.html#3)
- [IntroductionÂ ](converted.html#4)
  - [The Current State of AI CodingÂ ](converted.html#4)
  - [Â ](converted.html#4)
  - [The Promise of Autonomous ProgrammingÂ ](converted.html#4)
- [Adversarial CooperationÂ ](converted.html#5)
- [Â ](converted.html#6)
- [Â ](converted.html#6)
- [Context Window ManagementÂ ](converted.html#7)
- [Model UtilizationÂ ](converted.html#8)
- [Autocoding vs Single-Turn "Vibe Coding"Â ](converted.html#8)
- [Â ](converted.html#8)
- [Empirical Results and Case StudiesÂ ](converted.html#9)
  - [Â ](converted.html#9)
  - [Case Study: Calculator APIÂ ](converted.html#9)
    - [gooseÂ ](converted.html#9)
    - [autocoding with g3Â ](converted.html#9)
  - [Â ](converted.html#11)
  - [Case Study: Diff ViewerÂ ](converted.html#12)
  - [Â ](converted.html#12)
  - [Â ](converted.html#12)
  - [Â ](converted.html#13)
  - [Case Study: Mobile App Client in iOSÂ ](converted.html#13)
  - [Case Study: Git Repo Explorer with Branch Diff
    ViewingÂ ](converted.html#14)
- [Implications and RecommendationsÂ ](converted.html#18)
- [Â ](converted.html#18)
- [References and NotesÂ ](converted.html#18)
- [Â ](converted.html#18)
- [Â ](converted.html#18)
- [Â ](converted.html#18)

------------------------------------------------------------------------
