llmc/rlm/prompts.py:        first_line = doc.strip().split('\n')[0]
llmc/rlm/config.py:if sys.version_info >= (3, 11):
llmc/rlm/config.py:    max_session_budget_usd: float = 1.00
llmc/rlm/config.py:    max_subcall_depth: int = 5
llmc/rlm/config.py:    soft_limit_percentage: float = 0.80
llmc/rlm/config.py:    code_timeout_seconds: int = 30
llmc/rlm/config.py:    session_timeout_seconds: int = 300  # 5 minutes
llmc/rlm/config.py:    max_turns: int = 20
llmc/rlm/config.py:    root_temperature: float = 0.1
llmc/rlm/config.py:    root_max_tokens: int = 4096
llmc/rlm/config.py:    sub_temperature: float = 0.1
llmc/rlm/config.py:    sub_max_tokens: int = 1024
llmc/rlm/config.py:    chars_per_token: int = 4
llmc/rlm/config.py:    token_safety_multiplier: float = 1.2
llmc/rlm/config.py:            raise ValueError("code_timeout_seconds must be >= 1")
llmc/rlm/config.py:            raise ValueError("chars_per_token must be >= 1")
llmc/rlm/session.py:        self.session_id = str(uuid4())[:8]
llmc/rlm/session.py:        self._interception_counter = 0
llmc/rlm/session.py:            "context_slice": lambda start, length=10000: context[start : start + length],
llmc/rlm/session.py:        def context_search(pattern: str, max_results: int = 20) -> list[dict]:
llmc/rlm/session.py:                    line = context[: match.start()].count("\n") + 1
llmc/rlm/session.py:        def llm_query(prompt: str, max_tokens: int = 1024) -> str:
llmc/rlm/session.py:            estimated_output = min(max_tokens, 1000)
llmc/rlm/session.py:                    content = response.choices[0].message.content
llmc/rlm/session.py:            estimated_output = 2000  # Conservative for root
llmc/rlm/session.py:                assistant_message = response.choices[0].message.content
llmc/rlm/session.py:                        self._interception_counter += 1
llmc/rlm/session.py:            feedback = json.dumps(exec_results, indent=2)
llmc/rlm/governance/budget.py:if sys.version_info >= (3, 11):
llmc/rlm/governance/budget.py:    max_session_budget_usd: float = 1.00
llmc/rlm/governance/budget.py:    soft_limit_percentage: float = 0.80
llmc/rlm/governance/budget.py:    max_subcall_depth: int = 5  # Renamed from "recursion" - honest naming
llmc/rlm/governance/budget.py:    root_input_tokens: int = 0
llmc/rlm/governance/budget.py:    root_output_tokens: int = 0
llmc/rlm/governance/budget.py:    root_cost_usd: float = 0.0
llmc/rlm/governance/budget.py:    root_calls: int = 0
llmc/rlm/governance/budget.py:    sub_input_tokens: int = 0
llmc/rlm/governance/budget.py:    sub_output_tokens: int = 0
llmc/rlm/governance/budget.py:    sub_cost_usd: float = 0.0
llmc/rlm/governance/budget.py:    sub_calls: int = 0
llmc/rlm/governance/budget.py:    current_subcall_depth: int = 0
llmc/rlm/governance/budget.py:    max_subcall_depth_reached: int = 0
llmc/rlm/governance/budget.py:            self.state.root_calls += 1
llmc/rlm/governance/budget.py:            self.state.sub_calls += 1
llmc/rlm/governance/budget.py:        self.state.current_subcall_depth += 1
llmc/rlm/governance/budget.py:        self.state.current_subcall_depth = max(0, self.state.current_subcall_depth - 1)
llmc/rlm/sandbox/process_backend.py:        timeout_seconds: int = 30,
llmc/rlm/sandbox/process_backend.py:            root = name.split('.')[0]
llmc/rlm/sandbox/process_backend.py:            process.join(timeout=1)
llmc/rlm/sandbox/process_backend.py:                execution_time_ms=(time.perf_counter() - start) * 1000,
llmc/rlm/sandbox/process_backend.py:                execution_time_ms=(time.perf_counter() - start) * 1000,
llmc/rlm/sandbox/process_backend.py:            execution_time_ms=(time.perf_counter() - start) * 1000,
llmc/rlm/sandbox/intercept.py:        if len(node.targets) != 1:
llmc/rlm/sandbox/intercept.py:        target = node.targets[0]
llmc/rlm/sandbox/interface.py:    execution_time_ms: float = 0.0
llmc/rlm/sandbox/interface.py:    timeout_seconds: int = 30,
llmc/rlm/nav/treesitter_nav.py:                        start_line=node.start_point[0] + 1,
llmc/rlm/nav/treesitter_nav.py:                        end_line=node.end_point[0] + 1,
llmc/rlm/nav/treesitter_nav.py:                        signature=signature[:200],
llmc/rlm/nav/treesitter_nav.py:                        start_line=node.start_point[0] + 1,
llmc/rlm/nav/treesitter_nav.py:                        end_line=node.end_point[0] + 1,
llmc/rlm/nav/treesitter_nav.py:                        signature=signature[:200],
llmc/rlm/nav/treesitter_nav.py:    def outline(self, max_depth: int = 3) -> str:
llmc/rlm/nav/treesitter_nav.py:            if name.startswith(prefix) and name.count(".") == scope.count(".") + 1
llmc/rlm/nav/treesitter_nav.py:    def read(self, symbol: str, chunk_index: int = 0, max_chars: int = 8000) -> str:
llmc/rlm/nav/treesitter_nav.py:            available = list(self._symbols.keys())[:20]
llmc/rlm/nav/treesitter_nav.py:        full_code = '\n'.join(lines[node.start_line - 1:node.end_line])
llmc/rlm/nav/treesitter_nav.py:        header = f"# {symbol} (chunk {chunk_index + 1}/{len(chunks)})\n"
llmc/rlm/nav/treesitter_nav.py:            footer = f"\n# ... use read('{symbol}', {chunk_index + 1}) for next chunk"
llmc/rlm/nav/treesitter_nav.py:        current_size = 0
llmc/rlm/nav/treesitter_nav.py:            line_size = len(line) + 1
llmc/rlm/nav/treesitter_nav.py:                current_size = 0
llmc/rlm/nav/treesitter_nav.py:    def search(self, pattern: str, max_results: int = 20) -> list[SearchMatch]:
llmc/rlm/nav/treesitter_nav.py:                start_line = self.source[:match.start()].count('\n') + 1
llmc/rlm/nav/treesitter_nav.py:                end_line = self.source[:match.end()].count('\n') + 1
llmc/rlm/nav/treesitter_nav.py:                    text=match.group(0)[:200],
llmc/rlm/nav/treesitter_nav.py:                start_line=0,
llmc/rlm/nav/treesitter_nav.py:                end_line=0,
llmc/rlm/nav/treesitter_nav.py:                start_char=0,
llmc/rlm/nav/treesitter_nav.py:                end_char=0,
llmc/rlm/nav/treesitter_nav.py:        "nav_read": lambda symbol, chunk_index=0: nav.read(symbol, chunk_index),
llmc/rlm/nav/treesitter_nav.py:        "nav_search": lambda pattern, max_results=20: [
