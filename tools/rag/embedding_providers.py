from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional

import requests

from tools.rag.config import embedding_model_name, embedding_model_dim
from tools.rag.config_enrichment import get_embedding_config


class EmbeddingProvider(ABC):
    """
    Abstract base class for all embedding providers.
    Defines the interface for generating embeddings.
    """

    @abstractmethod
    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """
        Generates embeddings for a batch of texts.

        Args:
            texts: A list of strings to embed.

        Returns:
            A list of embeddings, where each embedding is a list of floats.
        """
        pass

    @abstractmethod
    def get_model_name(self) -> str:
        """Returns the name of the embedding model used by this provider."""
        pass

    @abstractmethod
    def get_dimension(self) -> int:
        """Returns the dimension of the embeddings generated by this provider."""
        pass


class OllamaEmbeddingProvider(EmbeddingProvider):
    """
    Embedding provider for Ollama models, specifically Nomic Embed Text.
    """
    def __init__(self, model_name: Optional[str] = None, api_base: Optional[str] = None):
        cfg = get_embedding_config()
        self._model_name = model_name or cfg.model
        self._api_base = api_base or cfg.api_base

        if not self._model_name:
            raise ValueError("OllamaEmbeddingProvider requires a model_name.")
        if not self._api_base:
            raise ValueError("OllamaEmbeddingProvider requires an api_base.")

    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """
        Generates embeddings for a batch of texts using the Ollama API.
        """
        if not texts:
            return []

        payload = {
            "model": self._model_name,
            "prompt": texts,  # Ollama's embeddings endpoint accepts a list of prompts
            "options": {"num_ctx": 4096} # Default context for Nomic Embed
        }
        
        try:
            # Ollama's embeddings API is typically at /api/embeddings
            response = requests.post(f"{self._api_base}/api/embeddings", json=payload, timeout=60)
            response.raise_for_status()
            data = response.json()
            
            # The 'embeddings' field will be a list of embedding vectors
            return data.get("embeddings", [])
        except requests.exceptions.RequestException as e:
            # Handle API errors, timeouts, network issues
            print(f"Error calling Ollama API for embeddings: {e}")
            raise
        except ValueError as e:
            print(f"Error decoding JSON response from Ollama API: {e}")
            raise

    def get_model_name(self) -> str:
        return self._model_name

    def get_dimension(self) -> int:
        # For Nomic Embed, default is 768. Can try to fetch from Ollama model info if needed.
        # For now, rely on configured value or a reasonable default.
        return embedding_model_dim()


# Factory function to get the configured embedding provider
def get_embedding_provider() -> EmbeddingProvider:
    """
    Returns the configured embedding provider based on llmc.toml.
    """
    cfg = get_embedding_config()
    
    provider_type = cfg.provider.lower()
    
    if provider_type == "ollama":
        return OllamaEmbeddingProvider(model_name=cfg.model, api_base=cfg.api_base)
    # Add other providers here as they are implemented
    # elif provider_type == "openai":
    #     return OpenAIEmbeddingProvider(...)
    else:
        raise ValueError(f"Unsupported embedding provider: {provider_type}")
